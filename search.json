[{"title":"String formatting C-style,format and f-string","url":"/string-formatting/","content":"## %\n| %s| %f | %d |\n| -------- | -------- | -------- |\n| string    | float     | integer     |\n### 1 variable\n```\n'I buy %d bread' % 2\n```\n![](https://i.imgur.com/N9szV6O.png)\n### 2 variables\n```\n'I buy %d bread and %d cake' % (2,3)\n```\n![](https://i.imgur.com/XHChvto.png)\n\n<!--more-->\n\n### 3 variables\n```\n'I buy %d bread ,%d cake and %d hats' % (2,3,4)\n```\n![](https://i.imgur.com/RcyshON.png)\n### different variable type \n```\n'I buy %d bread and 3 %s' % (2,'cake')\n```\n![](https://i.imgur.com/p8C9Phs.png)\n### how many digits\n```\n'1/6 is %f' % (1/6)\n```\n![](https://i.imgur.com/25QAyUN.png)\n```\n'1/6 is %.2f' % (1/6)\n```\n![](https://i.imgur.com/ao7ThCS.png)\n\n## format\n### 1 variable\n```\n'I buy {} bread'.format(2) \n```\n![](https://i.imgur.com/NGLtxF7.png)\n\n### 2 variables\n```\n'I buy {} bread and {} cake'.format(2,3)\n```\n![](https://i.imgur.com/XHChvto.png)\n### 3 variables\n```\n'I buy {} bread ,{} cake and {} hats'.format(2,3,4)\n```\n![](https://i.imgur.com/RcyshON.png)\n### different variable type \n```\n'I buy {} bread and 3 {}'.format(2,'cake')\n```\n![](https://i.imgur.com/p8C9Phs.png)\n\n### how many digits\n```\n'1/6 is {}'.format(1/6)\n```\n![](https://i.imgur.com/O5Wbqhx.png)\n\n```\n'1/6 is {:.2f}'.format(1/6)\n```\n![](https://i.imgur.com/UFgw1gI.png)\n\n### index\n```\n'I buy 1 {} and 3 {}'.format('cookie','cake')\n```\nor \n```\nx = 'cookie'\ny = 'cake'\n'I buy 1 {} and 3 {}'.format(x,y)\n```\n![](https://i.imgur.com/p3bkOTN.png)\n```\n'I buy 1 {0} and 3 {0}'.format('cookie','cake')\n```\n![](https://i.imgur.com/S5ixjmX.png)\n```\n'I buy 1 {1} and 3 {1}'.format('cookie','cake')\n```\n![](https://i.imgur.com/ruv0VGW.png)\n```\n'I buy 1 {1} and 3 {0}'.format('cookie','cake')\n```\n![](https://i.imgur.com/WvPqTqw.png)\n\n## f-string\n### 1 variable\n```\nf'I buy {2} bread' \n```\nor\n```\nnumber = 2\nf'I buy {number} bread' \n```\n![](https://i.imgur.com/NGLtxF7.png)\n\n### 2 variables\n```\nf'I buy {2} bread and {3} cake'\n```\n![](https://i.imgur.com/XHChvto.png)\n### 3 variables\n```\nf'I buy {2} bread ,{3} cake and {4} hats'\n```\n![](https://i.imgur.com/RcyshON.png)\n### different variable type \n```\nnumber = 2\nitem = 'cake'\nf'I buy {2} bread and 3 {item}'\n```\n![](https://i.imgur.com/p8C9Phs.png)\n\n### how many digits\n```\nf'1/6 is {1/6}'\n```\n![](https://i.imgur.com/O5Wbqhx.png)\n\n```\nf'1/6 is {1/6:.2f}'\n```\n![](https://i.imgur.com/UFgw1gI.png)","tags":["python"],"categories":["python"]},{"title":"Logistic regression","url":"/logistic-regression/","content":"## Sigmoid function\n$\\frac{1}{1+e^{-x}}$\n```python\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nx = np.arange(-10, 10, 0.1)\nf = 1 / (1 + np.exp(-x))\n\nplt.ylabel(\"F(x)\")\nplt.plot(x, f)\nplt.show()\n```\n![](https://i.imgur.com/Vk2cgNN.png)\n\n<!--more-->\n\n## Logistic regression\n$\\frac{1}{1+e^{-z}}=y'$ ; $z=a_1x_1+a_2x_2+...+b$\n\n$\\frac{1}{1+e^{-z}}=y'$\n\n$\\frac{e^{z}}{e^{z}+1}=\\frac{e^{z}\\cdot1}{e^{z}\\cdot(1+e^{-z)}}=y'$\n\n$e^{z}=y'(e^{z}+1)=y'\\cdot e^{z}+y'$\n\n$e^{z}-y'\\cdot e^{z}=y'$\n\n$e^{z}\\cdot(1-y')=y'$\n\n$e^{z}=\\frac{y'}{1-y'}$\n\n$z=ln(\\frac{y'}{1-y'})$\n\n## Odds\nSince $\\frac{1}{1+e^{-z}}=y'$ and range of $y'$ is $(0,1)$\n![](https://i.imgur.com/oxalPcV.png)\nWe can let $y'$ be the probability of sth happening (we predict)\nAnd let $1-y'$ be the probabilty of sth not happening (we predict)\nThen $\\frac{y'}{1-y'}=\\frac{happening}{not\\ happening}$ represents odds.\n\n## Cost function \n$\\sum_{x,y\\ \\in D}-y\\cdot ln(y')+-(1-y)\\cdot ln(1-y')$\n\n\n* ${x,y\\ \\in D}$ is the data set containing many labeled examples, which are   $(x,y)$ pairs.\n* $y$ is true value, either $0$ or $1$ means happening or not happening\n* $\\frac{1}{1+e^{-z}} = y'=y_{pred}\\in (0,1) \\ \\ ; \\ z=a_1x_1+a_2x_2+...+b$\n\n### Natural logarithm\n<!-- $ln(y')$\n![](https://i.imgur.com/pHBXHHg.png)\n\nDomain of $ln(y')$ is $(0,\\infty)$\nRange of $ln(y')$ is $(-\\infty,\\infty)$ -->\n\n$-ln(y')$\n<!-- ![](https://i.imgur.com/OyAJ03H.png) -->\n![](https://i.imgur.com/qnD8G4C.png)\n\nDomain of $-ln(y')$ is $(0,1)$\nRange of $-ln(y')$ is $(\\infty,0)$\n\n<!-- $ln(1-y')$\n![](https://i.imgur.com/sXeEujo.png) -->\n\n$-ln(1-y')$\n<!-- ![](https://i.imgur.com/oOWQZfv.png) -->\n![](https://i.imgur.com/4SR6lvU.png)\n\nDomain of $-ln(1-y')$ is $(0,1)$\nRange of $-ln(1-y')$ is $(0,\\infty)$\n\n### When y = 0 \nWhen $y = 0$ (true value, means sth not happening)\n$Cost=-0\\cdot ln(y')+-(1-0)\\cdot ln(1-y')=-ln(1-y')$\n\n![](https://i.imgur.com/4SR6lvU.png)\n\nIf our prediction $y'$ is close to $0$ \n(which means our prediction is close to true value), \nthen $Cost$ will be very **small**.\n\nOtherwise, if our prediction is close to $1$\n(which means our prediction is far from true value)\nthen $Cost$ will be very **large**\n\n### When y = 1\nWhen $y = 1$ (true value, means sth not happening)\n$Cost=-1\\cdot ln(y')+-(1-1)\\cdot ln(1-y')=-ln(y')$\n\n![](https://i.imgur.com/qnD8G4C.png)\n\nIf our prediction $y'$ is close to $0$ \n(which means our prediction is far from true value), \nthen $Cost$ will be very **large**.\n\nOtherwise, if our prediction is close to $1$\n(which means our prediction is close to true value)\nthen $Cost$ will be very **small**\n\n### Conclusion\nOur target is to minimize the $Cost$\nThus we need to get $y_{pred}=y'$ close to 1 when true value $y$ is $1$\nAnd get $y_{pred}=y'$ close to $0$ when true value $y$ is $0$\n\nRef : \n[邏輯迴歸 (Logistic Regression)](https://ithelp.ithome.com.tw/articles/10269006)\n[[資料分析&機器學習] 第3.3講：線性分類-邏輯斯回歸(Logistic Regression) 介紹](https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-3%E8%AC%9B-%E7%B7%9A%E6%80%A7%E5%88%86%E9%A1%9E-%E9%82%8F%E8%BC%AF%E6%96%AF%E5%9B%9E%E6%AD%B8-logistic-regression-%E4%BB%8B%E7%B4%B9-a1a5f47017e5)\n[Logistic Regression: Loss and Regularization](https://developers.google.com/machine-learning/crash-course/logistic-regression/model-training)\n[Machine Learning學習日記 — Coursera篇 (Week 3.2):Cost Function, Simplified Cost Function and Gradient Descent, Advanced Optimization](https://medium.com/@ken90242/machine-learning%E5%AD%B8%E7%BF%92%E6%97%A5%E8%A8%98-coursera%E7%AF%87-week-3-2-cost-2e7aa00e8c4a)\n","tags":["python","machine learning"],"categories":["python"]},{"title":"Difference between simple assignment , view and deep copy","url":"/simple-assignment-view-deep-copy/","content":"## simple assignment\n```python\na = np.array([[1,2],[3,4]])\nprint(\"a\\n\",a)\nb = a\nprint(\"b\\n\",b)\n```\n![](https://i.imgur.com/HVCrMXp.png)\n\n<!--more-->\n\n### change shape\n```python\nb.shape = (4,1)\nprint(\"b\\n\",b)\nprint(\"a\\n\",a)\n```\n![](https://i.imgur.com/ylxCV1C.png)\n### change value\n```python\nb[3,0] = 999\nprint(\"b\\n\",b)\nprint(\"a\\n\",a)\n```\n![](https://i.imgur.com/dYxJq5B.png)\n\n## view.()  : shadow copy\n```python\na = np.array([[1,2],[3,4]])\nprint(\"a\\n\",a)\nc = a.view()\nprint(\"c\\n\",c)\n```\n![](https://i.imgur.com/OdwNvzz.png)\n\n### change shape\n####  notice that changing the shape of c doesn't change the shape of b\n```python\nc.shape = (4,1)\nprint(\"c\\n\",c)\nprint(\"a\\n\",a)\n```\n![](https://i.imgur.com/4vTghA4.png)\n\n### change value\n```python\nc[3,0] = 999\nprint(\"c\\n\",c)\nprint(a)\n```\n![](https://i.imgur.com/FkqABL6.png)\n\n## .copy() : deep copy\n```python\na = np.array([[1,2],[3,4]])\nprint(\"a\\n\",a)\nd = a.copy()\nprint(\"d\\n\",d)\n```\n![](https://i.imgur.com/67s3Dmr.png)\n\n### change shape\n####  notice that changing the shape of c doesn't change the shape of d\n```python\nd.shape = (4,1)\nprint(\"d\\n\",d)\nprint(\"a\\n\",a)\n```\n![](https://i.imgur.com/dUtQm0l.png)\n\n### change value\n#### notice that changing the shape of c doesn't change the value of d\n```python\nd[3,0] = 999\nprint(\"d\\n\",d)\nprint(\"a\\n\",a)\n```\n![](https://i.imgur.com/yooGdK7.png)\n\n## Conclusion\n\n|  | simple assignment| .view() | .copy()  |\n| -------- | -------- | -------- | -------- |\n| Change shape of it affects the original item |  O  | X     | X     |\n| Change value of it affects the original item |  O  | O  | X |\n\nref [NumPy 1.14 教學 – #06 簡易指定(Simple Assignments), 檢視(Views), 深度拷貝(Deep Copy)](https://www.brilliantcode.net/1130/numpy-tutorial-simple-assignments-views-deep-copy/)","tags":["python","numpy"],"categories":["python"]},{"title":"gradient descent and linear regression","url":"/gradient-descent-linear-regression/","content":"\n## datasets.make_regression\n```python\nimport matplotlib.pyplot as plt\nimport numpy\nfrom sklearn import datasets\nfrom numpy import abs\n\n# noise = 10 make it more scttered\nregressionData = datasets.make_regression(100, 1, noise=10)\n```\n<!--more-->\n\n## y = ax+b and scatterplot\n```python\n# scatterplot\nplt.scatter(regressionData[0], regressionData[1], c='red', marker='*')\n\n# define initial m & b (it can be chosen by your own)\ninit_m = 10\ninit_b = 10\nlearning_rate = 0.1\nrange1 = [-5, 5]\n\n# x axis frome -5 ~ 5 (range1) \nplt.xlim(range1)\n\n# y=m*x+b\nplt.plot(range1, init_m * numpy.array(range1) + init_b)  \nplt.show()\n```\n![](https://i.imgur.com/Sf4PgPy.png)\n\n## MSE  ( Mean squared error )\n$f(m,b)=MSE=\\frac{1}{N}\\ \\sum_{i=1}^{n} (y_i-(mx_i+b))^2$\ngoal : minimize $f(m,b)$ \n\n## Gradient descent\nuse gradient descent to  find the minimum\n \n$\\frac{\\partial f}{\\partial m}= \\frac{1}{N}\\ 2 (y_i-(mx_i+b))(-x_i)$\n\n$\\frac{\\partial f}{\\partial b}= \\frac{1}{N}\\ 2 (y_i-(mx_i+b))(-1)$\n\n$\\nabla C= \\begin{bmatrix}\n\\frac{1}{N}\\ \\sum_{i=1}^{n}(2)(y_i-(mx_i+b))(-x_i)\\\\\n\\frac{1}{N} \\sum_{i=1}^{n}(2)(y_i-(mx_i+b))(-1)\\   \n\\end{bmatrix}$\n\n\n$\\begin{bmatrix}\nm^{t+1} \\\\\nb^{t+1} \n\\end{bmatrix}= -\\eta\\nabla C=-\\eta\\begin{bmatrix}\n\\frac{1}{N}\\ \\sum_{i=1}^{n}(-2x_i)(y_i-(mx_i+b))\\\\\n\\frac{1}{N} \\sum_{i=1}^{n} (-2) (y_i-(mx_i+b))\\   \n\\end{bmatrix}$\n\n## Code\n```python\ndef update_weight(m, b, X, Y, learning_rate):\n    m_deriv = 0\n    b_deriv = 0\n    N = len(X)\n    for i in range(N):\n        m_deriv += -2 * X[i] * (Y[i] - (m * X[i] + b))\n        b_deriv += -2 * (Y[i] - (m * X[i] + b))\n    m -= (m_deriv / N) * learning_rate\n    b -= (b_deriv / N) * learning_rate\n    return m, b\n\n\ndef cost(m, b, X, Y):\n    cost = 0\n    for i in range(len(X)):\n        cost += (Y[i] - (m * X[i] + b)) ** 2\n    return cost / (len(X))\n\n```\nNote that we have constant 2 after derivative,\nwe can technically take 1/2 MSE as our cost function,\nand it will make it more convenient to calculate\n\n## Cost function \nuse 1/2 MSE as cost function\n\n$C(m,b)=\\frac{1}{2N}\\ \\sum_{i=1}^{n} (y_i-(mx_i+b))^2$\ngoal : minimize $C(m,b)$ \n\n## Gradient descent\nuse gradient descent to  find the minimum\n \n$\\frac{\\partial C}{\\partial m}= \\frac{1}{2N}\\ 2 (y_i-(mx_i+b))(-x_i)$\n\n$\\frac{\\partial C}{\\partial b}= \\frac{1}{2N}\\ 2 (y_i-(mx_i+b))(-1)$\n\n$\\nabla C= \\begin{bmatrix}\n\\frac{1}{2N}\\ \\sum_{i=1}^{n}(2)(y_i-(mx_i+b))(-x_i)\\\\\n\\frac{1}{2N} \\sum_{i=1}^{n}(2)(y_i-(mx_i+b))(-1)\\   \n\\end{bmatrix}$\n\n\n$\\begin{bmatrix}\nm^{t+1} \\\\\nb^{t+1} \n\\end{bmatrix}= -\\eta\\nabla C=-\\eta\\begin{bmatrix}\n\\frac{1}{N}\\ \\sum_{i=1}^{n}(-x_i)(y_i-(mx_i+b))\\\\\n\\frac{1}{N} \\sum_{i=1}^{n} (-1) (y_i-(mx_i+b))\\   \n\\end{bmatrix}$\n\n## Code\n```python\ndef update_weight(m, b, X, Y, learning_rate):\n    m_deriv = 0\n    b_deriv = 0\n    N = len(X)\n    for i in range(N):\n        m_deriv += -1 * X[i] * (Y[i] - (m * X[i] + b))\n        b_deriv += -1 * (Y[i] - (m * X[i] + b))\n    m -= (m_deriv / N) * learning_rate\n    b -= (b_deriv / N) * learning_rate\n    return m, b\n\n\ndef cost(m, b, X, Y):\n    cost = 0\n    for i in range(len(X)):\n        cost += (Y[i] - (m * X[i] + b)) ** 2\n    return cost / (2 * len(X))\n```\n\n## Iteration\n```python\ninit_cost = cost(init_m, init_b, regressionData[0], regressionData[1])\nprint(\"init cost=\", init_cost)\n\ncurrent_m = init_m\ncurrent_b = init_b\nlr = 0.1\nfor _ in range(30):\n    new_m, new_b = update_weight(current_m, current_b, regressionData[0], regressionData[1], lr)\n    new_cost = cost(new_m, new_b, regressionData[0], regressionData[1])\n    print(\"cost=\", new_cost)\n    plt.plot(range1, new_m * range1 + new_b)\n    plt.scatter(regressionData[0], regressionData[1], c='red', marker='*')\n    plt.xlim(range1)\n    plt.show()\n    current_m = new_m\n    current_b = new_b\n```\nRef [ML Glossary Linear Regression](https://ml-cheatsheet.readthedocs.io/en/latest/linear_regression.html)\n","tags":["python","sklearn","machine learning"],"categories":["python","machine learning"]},{"title":"Difference between python np.array shape (n,) and (n,1)","url":"/python-np-array-shape/","content":"## (n,)\n```python\nimport numpy as np\nshape_demo = np.array([1,2,3,4])\nprint(shape_demo)\nprint(shape_demo.shape)\n```\n![](https://i.imgur.com/wMQiUT8.png)\n## (n,1)\n```python\nshape_demo_1 = np.array([[1],[2],[3],[4]])\nprint(shape_demo_1)\nprint(shape_demo_1.shape)\n```\n![](https://i.imgur.com/EyZlwjd.png)\n\n<!--more-->\n\n## (2,4)\n```python\nshape_demo_2 = np.array([[1,2,3,4],[5,6,7,8]])\nprint(shape_demo_2)\nprint(shape_demo_2.shape)\n```\n![](https://i.imgur.com/1BaJlT6.png)\n\n## sklearn datasets.make_regression\n```python\nimport matplotlib.pyplot as plt\nimport numpy\nfrom sklearn import datasets\n\n#n_samples=10 n_features=1\nregressionData = datasets.make_regression(10, 1, noise=10)\n```\ntype of regressionData is tuple(2 items) \n(ndarray with shape (10, 1), ndarray with shape (10,))\n```python\ntype(regressionData)\n```\n![](https://i.imgur.com/ghWTR1Z.png)\n```python\nregressionData[0]\n```\n![](https://i.imgur.com/Y1h44Sc.png)\n```python\nregressionData[1]\n```\n![](https://i.imgur.com/IN4Q7RI.png)\n\nref [[Day27]機器學習：建立線性迴歸資料與預測！](https://ithelp.ithome.com.tw/articles/10197248)\nref [numpy.array 的shape属性理解](https://blog.csdn.net/liuweiyuxiang/article/details/79384435)\nref [python 里 np.array 的shape ( ,)与( ,1)的区别](https://blog.csdn.net/weixin_39449570/article/details/78645618)","tags":["python","sklearn"],"categories":["python"]},{"title":"Install nvidia driver 515 | cuda 11.7 | docker | docker compose | nvidia container | anaconda on ubuntu 22.04","url":"/install-nvidia-driver-cuda-docker-compose-container-anaconda/","content":"## Remove\n### remove nvidia driver \n```bash\nsudo apt-get --purge remove nvidia*\nsudo apt autoremove\n```\n### remove cuda\n```bash\nsudo apt-get --purge remove \"*cublas*\" \"cuda*\"\n```\n## Nvidia driver\n```bash\nsudo lshw -numeric -C display\nsudo apt-get purge nvidia*\nsudo add-apt-repository ppa:graphics-drivers\nsudo apt-get update\nsudo apt upgrade\nubuntu-drivers list\nsudo apt install nvidia-driver-515\nsudo reboot\nnvidia-smi\n```\n<!--more-->\n\n## Nvidia cuda 11.7\n```bash\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin\nsudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/11.7.0/local_installers/cuda-repo-ubuntu2204-11-7-local_11.7.0-515.43.04-1_amd64.deb\nsudo dpkg -i cuda-repo-ubuntu2204-11-7-local_11.7.0-515.43.04-1_amd64.deb\nsudo cp /var/cuda-repo-ubuntu2204-11-7-local/cuda-*-keyring.gpg /usr/share/keyrings/\nsudo apt-get update\nsudo apt-get -y install cuda\n```\nRef : [CUDA Toolkit 11.7 Downloads](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=22.04&target_type=deb_local)\n\n```\nsudo nano ~/.bashrc\n```\n```\nexport PATH=/usr/local/cuda-11.7/bin${PATH:+:${PATH}}\nexport LD_LIBRARY_PATH=/usr/local/cuda-11.7/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n```\nRef : [Cuda-quick-start-guide](https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html#debian-x86_64-run)\n```\nsudo reboot\n```\n\n\n## Docker\n```bash\nsudo apt-get update\n\nsudo apt-get install \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n    \nsudo mkdir -p /etc/apt/keyrings\n```\n```\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n```\n```\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n```\n## Docker compose\n```bash\nsudo apt-get update\n\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n```\n### add user group\n```bash\nsudo groupadd docker\n\nsudo usermod -aG docker $USER\n\ndocker run hello-world\n```\nRef : [Install Docker Engine on Ubuntu](https://docs.docker.com/engine/install/ubuntu/)\n\n## Nvidia runtime\n```bash\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\\n      && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n      && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\\n            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n            sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n```\n```bash\nsudo apt-get update\nsudo apt-get install -y nvidia-docker2\nsudo systemctl restart docker\n```\nRef : [Setting up NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)\n\n## Annaconda\n### Download .sh \nhttps://www.anaconda.com/products/distribution\n\n### Check hashes \n(should be same with https://docs.anaconda.com/anaconda/install/hashes/lin-3-64/)\n```bash\nsudo sha256sum Anaconda3-2022.05-Linux-x86_64.sh\n```\n### Run Shell Script \n```bash\nsudo bash Anaconda3-2022.05-Linux-x86_64.sh\n```\n### Conda init\n```bash\nInstallation finished.\nDo you wish the installer to initialize Anaconda3\nby running conda init? [yes|no]\n```\npress yes \nopen new terminal\n```bash\nsource ~/.bashrc\n```\nRef : [如何在 Ubuntu 20.04 上安装 Anaconda](https://www.itcoder.tech/posts/how-to-install-anaconda-on-ubuntu-20-04/)","tags":["linux","nvidia"],"categories":["linux"]},{"title":"Disable ubuntu kernel auto update","url":"/disable-ubuntu-kernel-auto-update-en/","content":"## Software & updates\n![](https://i.imgur.com/DNIg1o6.png)\n\n## Check current kernel (5.15.0-37)\n```bash\nuname -a\n```\n![](https://i.imgur.com/6E9xrFU.png)\n\n<!-- more -->\n\n## Show all kernel\n```bash\ndpkg -l | grep linux\n```\n![](https://i.imgur.com/eNusExx.png)\n\n## Hold specific version kernel (5.15.0-37)\n```bash\nsudo apt-mark hold linux-headers-5.15.0-37 \\\nlinux-headers-5.15.0-37-generic \\\nlinux-image-5.15.0-37-generic \\\nlinux-modules-5.15.0-37-generic \\\nlinux-modules-extra-5.15.0-37-generic\n```\n## Check kernel hold \n```bash\ndpkg --get-selections | grep hold\n```\n![](https://i.imgur.com/sAyz3JH.png)\n\nRef : [Ubuntu 禁止内核更新](https://blog.csdn.net/hanchaoo073092/article/details/118330986) \n\n","tags":["linux"],"categories":["linux"]}]